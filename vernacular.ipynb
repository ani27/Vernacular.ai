{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "train = pd.read_csv(\"copied_to_txt.txt\", delimiter=\"\\t\", header=0)\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     category                                           sentence subcategory\n",
      "0     ï»¿DESC  How did serfdom develop in and then leave Russ...      manner\n",
      "1        ENTY  What films featured the character Popeye Doyle...      cremat\n",
      "2        DESC  How can I find a list of celebrities ' real na...      manner\n",
      "3        ENTY  What fowl grabs the spotlight after the Chines...      animal\n",
      "4        ABBR                  What is the full form of .com ?\\n         exp\n",
      "5         HUM  What contemptible scoundrel stole the cork fro...         ind\n",
      "6         HUM  What team did baseball 's St. Louis Browns bec...          gr\n",
      "7         HUM                  What is the oldest profession ?\\n       title\n",
      "8        DESC                         What are liver enzymes ?\\n         def\n",
      "9         HUM  Name the scar-faced bounty hunter of The Old W...         ind\n",
      "10        NUM                    When was Ozzy Osbourne born ?\\n        date\n",
      "11       DESC  Why do heavier objects travel downhill faster ?\\n      reason\n",
      "12        HUM               Who was The Pride of the Yankees ?\\n         ind\n",
      "13        HUM                              Who killed Gandhi ?\\n         ind\n",
      "14       ENTY  What is considered the costliest disaster the ...       event\n",
      "15        LOC  What sprawling U.S. state boasts the most airp...       state\n",
      "16       DESC  What did the only repealed amendment to the U....        desc\n",
      "17        NUM  How many Jews were executed in concentration c...       count\n",
      "18       DESC                  What is `` Nine Inch Nails '' ?\\n         def\n",
      "19       DESC              What is an annotated bibliography ?\\n         def\n",
      "20        NUM                 What is the date of Boxing Day ?\\n        date\n",
      "21       ENTY  What articles of clothing are tokens in Monopo...       other\n",
      "22        HUM                         Name 11 famous martyrs .\\n         ind\n",
      "23       DESC                      What 's the Olympic motto ?\\n        desc\n",
      "24       DESC    What is the origin of the name ` Scarlett ' ?\\n        desc\n",
      "25       ENTY  What 's the second-most-used vowel in English ?\\n      letter\n",
      "26        HUM            Who was the inventor of silly putty ?\\n         ind\n",
      "27        LOC  What is the highest waterfall in the United St...       other\n",
      "28       ENTY             Name a golf course in Myrtle Beach .\\n       other\n",
      "29        LOC        Which two states enclose Chesapeake Bay ?\\n       state\n",
      "...       ...                                                ...         ...\n",
      "5422     DESC  How do I legally make my own will and testamen...      manner\n",
      "5423     DESC               How do you make the color purple ?\\n      manner\n",
      "5424     ENTY  What beer 's name is translated as `` lion bre...        food\n",
      "5425      HUM  What has been the most common Christian name o...         ind\n",
      "5426      NUM  How many cherubs are there on a Trivial Pursui...       count\n",
      "5427     DESC  How can I search for a word within my own webp...      manner\n",
      "5428      NUM                  How many people live in Chile ?\\n       count\n",
      "5429     ENTY    What sport do the Cleaveland Cavaliers play ?\\n       sport\n",
      "5430      LOC  What European country 's monarchy was restored...     country\n",
      "5431     DESC  Why are sometimes your hands cold , but the re...      reason\n",
      "5432      HUM  What English explorer discovered and named Vir...         ind\n",
      "5433     ENTY  What war added jeep and quisling to the Englis...       event\n",
      "5434      LOC          What country is home to Heineken beer ?\\n     country\n",
      "5435      HUM  What people make up half the Soviet Union 's p...          gr\n",
      "5436     ENTY                       What money was used here ?\\n    currency\n",
      "5437      NUM                 When did Charles Lindbergh die ?\\n        date\n",
      "5438      NUM  How many athletes did Puerto Rico enter in the...       count\n",
      "5439      LOC                  What is the highest continent ?\\n       other\n",
      "5440      HUM      Who used to make cars with rotary engines ?\\n          gr\n",
      "5441     DESC  What are my legal rights in an automobile repo...        desc\n",
      "5442     DESC  What is the meaning of caliente , in English ,...         def\n",
      "5443      LOC  Where can I find information on becoming a jou...       other\n",
      "5444     ENTY  What did Jack exchange with the butcher for a ...       other\n",
      "5445      LOC  In what city does Maurizio Pellegrin now live ?\\n        city\n",
      "5446      HUM                           Who was Buffalo Bill ?\\n        desc\n",
      "5447     ENTY          What 's the shape of a camel 's spine ?\\n       other\n",
      "5448     ENTY         What type of currency is used in China ?\\n    currency\n",
      "5449      NUM                  What is the temperature today ?\\n        temp\n",
      "5450      NUM            What is the temperature for cooking ?\\n        temp\n",
      "5451     ENTY               What currency is used in Australia ?    currency\n",
      "\n",
      "[5452 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "training = []\n",
    "category=[]\n",
    "subcategory=[]\n",
    "sentence=[]\n",
    "with open('copied_to_txt.txt', 'r') as fingood:\n",
    "     for review in fingood.readlines():\n",
    "            cat = 0\n",
    "            subcat = 0\n",
    "            for i,c in enumerate(review):\n",
    "                if(review[i] == ':'and cat == 0):\n",
    "                    cat = i\n",
    "                if(review[i] == \" \" and subcat == 0):\n",
    "                    subcat = i\n",
    "           \n",
    "            category.append(review[:cat])\n",
    "            subcategory.append(review[cat+1:subcat])\n",
    "            sentence.append(review[subcat+1:])\n",
    "            \n",
    "training = pd.DataFrame( data={\"category\":category, \"subcategory\":subcategory, \"sentence\":sentence} )\n",
    "print (training)\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 documents\n",
      "6 category ['LOC', 'ENTY', 'NUM', 'ABBR', 'HUM', 'DESC']\n",
      "47 subcategory ['cremat', 'manner', 'animal', 'exp', 'ind', 'gr', 'title', 'def', 'date', 'reason', 'event', 'state', 'desc', 'count', 'other', 'letter', 'religion', 'food', 'country', 'color', 'termeq', 'city', 'body', 'dismed', 'mount', 'money', 'product', 'period', 'substance', 'sport', 'plant', 'techmeth', 'volsize', 'instru', 'abb', 'speed', 'word', 'lang', 'perc', 'code', 'dist', 'temp', 'symbol', 'ord', 'veh', 'weight', 'currency']\n",
      "6409 unique stemmed words\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "words = []\n",
    "cat = []\n",
    "subcat=[]\n",
    "documents = []\n",
    "ignore_words = ['\\n']\n",
    "numrange = training['sentence'].size\n",
    "\n",
    "for i in range( 1, numrange ):\n",
    "    w = nltk.word_tokenize(training['sentence'][i])\n",
    "    words.extend(w)\n",
    "    #documents.append((w, training['category'][i]))\n",
    "    #documents.append((w, training['subcategory'][i]))\n",
    "    if training['category'][i] not in cat:\n",
    "        cat.append(training['category'][i])\n",
    "    if training['subcategory'][i] not in subcat:\n",
    "        subcat.append(training['subcategory'][i])\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = list(set(words))\n",
    "\n",
    "# remove duplicates\n",
    "cat = list(set(cat))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(cat), \"category\",cat)\n",
    "print (len(subcat), \"subcategory\",subcat)\n",
    "print (len(words), \"unique stemmed words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "   \n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review, \"lxml\").get_text() \n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = review_text.lower().split()                             \n",
    "   \n",
    "    # 3. Join the words back and return the result.\n",
    "    return( \" \".join( words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews = training[\"sentence\"].size\n",
    "output_cat = []\n",
    "output_subcat = []\n",
    "output_empty_cat = [0] * len(cat)\n",
    "output_empty_subcat = [0] * len(subcat)\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "for i in range( 1, num_reviews ):\n",
    "    \n",
    "    output_row_cat = list(output_empty_cat)\n",
    "    output_row_cat[cat.index(training[\"category\"][i])] = 1\n",
    "    output_cat.append(output_row_cat)\n",
    "    output_row_subcat = list(output_empty_subcat)\n",
    "    output_row_subcat[subcat.index(training[\"subcategory\"][i])] = 1\n",
    "    output_subcat.append(output_row_subcat)\n",
    "\n",
    "    clean_train_reviews.append( review_to_words( training[\"sentence\"][i] ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5451, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#BAg of words of 5000 features\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,stop_words = None, max_features = 5000)\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "train_data_features = train_data_features.toarray()\n",
    "print (train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print (output_cat[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print (output_subcat[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta after 10 iterations:0.224787134933\n",
      "delta after 20 iterations:0.208270172093\n",
      "delta after 30 iterations:0.179465774059\n",
      "delta after 40 iterations:0.148365536693\n",
      "delta after 50 iterations:0.126100320479\n",
      "delta after 60 iterations:0.114380013536\n",
      "delta after 70 iterations:0.1051736809\n",
      "delta after 80 iterations:0.0971312561341\n",
      "delta after 90 iterations:0.0899750933139\n",
      "delta after 100 iterations:0.0837035012928\n",
      "delta after 110 iterations:0.0781187109646\n",
      "delta after 120 iterations:0.0732648974114\n",
      "delta after 130 iterations:0.0690619673481\n",
      "delta after 140 iterations:0.0653209456086\n",
      "delta after 150 iterations:0.0620947956334\n",
      "delta after 160 iterations:0.0593276165797\n",
      "delta after 170 iterations:0.0569157609741\n",
      "delta after 180 iterations:0.054777361297\n",
      "delta after 190 iterations:0.0528523561749\n",
      "delta after 200 iterations:0.0511013007598\n",
      "delta after 210 iterations:0.0494885931415\n",
      "delta after 220 iterations:0.0479848953192\n",
      "delta after 230 iterations:0.0465904862787\n",
      "delta after 240 iterations:0.0453220712598\n",
      "delta after 250 iterations:0.0441794757818\n",
      "delta after 260 iterations:0.0431578458192\n",
      "delta after 270 iterations:0.0422561929465\n",
      "delta after 280 iterations:0.0414856047698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta after 290 iterations:0.0408422174799\n",
      "delta after 300 iterations:0.0403088818398\n",
      "delta after 310 iterations:0.0398658130998\n",
      "delta after 320 iterations:0.0394865660814\n",
      "delta after 330 iterations:0.0391500974728\n",
      "delta after 340 iterations:0.0388697874149\n",
      "delta after 350 iterations:0.0386358149554\n",
      "delta after 360 iterations:0.0383400077859\n",
      "delta after 370 iterations:0.0380613105602\n",
      "delta after 380 iterations:0.0378358997098\n",
      "delta after 390 iterations:0.0375993858461\n",
      "delta after 400 iterations:0.037496846851\n",
      "delta after 410 iterations:0.0374406593611\n",
      "delta after 420 iterations:0.0373900231134\n",
      "delta after 430 iterations:0.0373289999834\n",
      "delta after 440 iterations:0.0372224770653\n",
      "delta after 450 iterations:0.0370802487295\n",
      "delta after 460 iterations:0.0370695514604\n",
      "delta after 470 iterations:0.0370364815588\n",
      "delta after 480 iterations:0.0370202646162\n",
      "delta after 490 iterations:0.0369850289603\n",
      "break: 0.0370426851619 > 0.0369850289603\n"
     ]
    }
   ],
   "source": [
    "#Training neural network for Category part\n",
    "hidden_neurons = 400\n",
    "np.random.seed(8)\n",
    "theta1 = 2*np.random.random((len(X[0]), hidden_neurons)) - 1\n",
    "theta2 = 2*np.random.random((hidden_neurons, len(cat))) - 1\n",
    "theta1.size\n",
    "lamda = 3\n",
    "\n",
    "\n",
    "\n",
    "X = (train_data_features)\n",
    "y = (output_cat)\n",
    "epochs = 1000\n",
    "alpha = .003\n",
    "dell_theta1 = np.zeros_like(theta1)\n",
    "dell_theta2 = np.zeros_like(theta2)\n",
    "last_mean_error = 1\n",
    "start_X = X[1:1500]\n",
    "final_Y = y[1:1500]\n",
    "for j in iter(range(epochs+1)):\n",
    "    layer_2 = sigmoid(np.dot(start_X, theta1))\n",
    "    layer_3 = sigmoid(np.dot(layer_2, theta2))\n",
    "    layer_3_error =   final_Y - layer_3\n",
    "    if (j% 10) == 0 and j > 5:\n",
    "         # if this 10k iteration's error is greater than the last iteration, break out\n",
    "        if np.mean(np.abs(layer_3_error)) < last_mean_error:\n",
    "            print (\"delta after \"+str(j)+\" iterations:\" + str(np.mean(np.abs(layer_3_error))) )\n",
    "            last_mean_error = np.mean(np.abs(layer_3_error))\n",
    "        else:\n",
    "            print (\"break:\", np.mean(np.abs(layer_3_error)), \">\", last_mean_error )\n",
    "            break\n",
    "\n",
    "    layer_2_error = (layer_3_error.dot(theta2.T))*sigmoid_output_to_derivative(layer_2)\n",
    "    #layer_3_delta_sigma = layer_3_error * sigmoid_output_to_derivative(layer_2)\n",
    "    #layer_2_error = layer_3_delta_sigma.dot(theta2.T)\n",
    "    #layer_2_delta_sigma = layer_2_error * sigmoid_output_to_derivative(layer_2)\n",
    "        \n",
    "    dell_theta2 = (layer_2.T.dot(layer_3_error))\n",
    "    dell_theta2 += lamda*theta2\n",
    "    dell_theta1 = (start_X.T.dot(layer_2_error))\n",
    "    dell_theta1 += lamda*theta1\n",
    "    theta1 += alpha * dell_theta1\n",
    "    theta2 += alpha * dell_theta2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who portrayed Prewett in From Here to Eternity ?\n",
      "\n",
      "HUM\n",
      "6 category ['LOC', 'ENTY', 'NUM', 'ABBR', 'HUM', 'DESC']\n",
      "[ 0.  0.  0.  0.  1.  0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "#Result Check\n",
    "#print (theta1.size)\n",
    "n=4357\n",
    "l0 = X[n]\n",
    "print (training['sentence'][n+1])\n",
    "print (training['category'][n+1])\n",
    "print (len(cat), \"category\",cat)\n",
    "# matrix multiplication of input and hidden layer\n",
    "l1 = sigmoid(np.dot(l0, theta1))\n",
    "# output layer\n",
    "l2 = sigmoid(np.dot(l1, theta2))\n",
    "\n",
    "print (l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0973215213\n"
     ]
    }
   ],
   "source": [
    "#cross-validation for categories\n",
    "sum  = [0,0,0,0,0,0]\n",
    "for i in range( 4000, 4500 ):\n",
    "    l0 = X[i]\n",
    "    l1 = sigmoid(np.dot(l0, theta1))\n",
    "    l2 = sigmoid(np.dot(l1, theta2))\n",
    "    output_cat = np.asarray(output_cat)\n",
    "    #print (l2)\n",
    "    #print (output_cat[i])\n",
    "    sum = sum + (l2 - output_cat[i])\n",
    "    \n",
    "print (np.mean(np.abs(sum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta after 10 iterations:0.025563394548\n",
      "delta after 20 iterations:0.0233061564591\n",
      "delta after 30 iterations:0.0220858033984\n",
      "delta after 40 iterations:0.0215798781087\n",
      "delta after 50 iterations:0.0212764833332\n",
      "delta after 60 iterations:0.0205853841501\n",
      "delta after 70 iterations:0.0196498567667\n",
      "delta after 80 iterations:0.0187849511121\n",
      "delta after 90 iterations:0.017986325975\n",
      "delta after 100 iterations:0.0172515514365\n",
      "delta after 110 iterations:0.0165922622597\n",
      "delta after 120 iterations:0.0159805653848\n",
      "delta after 130 iterations:0.0154014270289\n",
      "delta after 140 iterations:0.0148203946705\n",
      "delta after 150 iterations:0.0142621680648\n",
      "delta after 160 iterations:0.0137040733542\n",
      "delta after 170 iterations:0.0131268981937\n",
      "delta after 180 iterations:0.0125645323366\n",
      "delta after 190 iterations:0.0119991663579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta after 200 iterations:0.0114552487473\n",
      "delta after 210 iterations:0.0109174146985\n",
      "delta after 220 iterations:0.0104064945212\n",
      "delta after 230 iterations:0.00993849367539\n",
      "delta after 240 iterations:0.00952203529048\n",
      "delta after 250 iterations:0.00915136819678\n",
      "delta after 260 iterations:0.00881714016709\n",
      "delta after 270 iterations:0.00848538211072\n",
      "delta after 280 iterations:0.00815710401054\n",
      "delta after 290 iterations:0.00783733191012\n",
      "delta after 300 iterations:0.00754407436434\n",
      "delta after 310 iterations:0.00727145979737\n",
      "delta after 320 iterations:0.00701598562593\n",
      "delta after 330 iterations:0.00676393089294\n",
      "delta after 340 iterations:0.00654734792195\n",
      "delta after 350 iterations:0.00635681627688\n",
      "delta after 360 iterations:0.00618044916998\n",
      "delta after 370 iterations:0.00601896185328\n",
      "delta after 380 iterations:0.00585438429912\n",
      "delta after 390 iterations:0.00570808228464\n",
      "delta after 400 iterations:0.00558667640516\n",
      "delta after 410 iterations:0.00547209342917\n",
      "delta after 420 iterations:0.00534690008342\n",
      "delta after 430 iterations:0.00522298851768\n",
      "delta after 440 iterations:0.00510550060656\n",
      "delta after 450 iterations:0.00500807273699\n",
      "delta after 460 iterations:0.00494357883758\n",
      "delta after 470 iterations:0.00488944138347\n",
      "delta after 480 iterations:0.00482397648025\n",
      "delta after 490 iterations:0.00475401823951\n",
      "delta after 500 iterations:0.00469155565884\n",
      "delta after 510 iterations:0.00463941200612\n",
      "delta after 520 iterations:0.00461337067133\n",
      "delta after 530 iterations:0.00459390090779\n",
      "delta after 540 iterations:0.00455520021673\n",
      "delta after 550 iterations:0.00451623759374\n",
      "delta after 560 iterations:0.00448378342552\n",
      "delta after 570 iterations:0.00446793921012\n",
      "delta after 580 iterations:0.00444154329971\n",
      "delta after 590 iterations:0.00440102178626\n",
      "delta after 600 iterations:0.00434766109505\n",
      "delta after 610 iterations:0.00434024976366\n",
      "delta after 620 iterations:0.00429093228954\n",
      "delta after 630 iterations:0.00426355931356\n",
      "delta after 640 iterations:0.00421261625874\n",
      "delta after 650 iterations:0.00417869686176\n",
      "delta after 660 iterations:0.00413081803045\n",
      "delta after 670 iterations:0.0041161590067\n",
      "delta after 680 iterations:0.00410746547442\n",
      "delta after 690 iterations:0.00405950534106\n",
      "delta after 700 iterations:0.0040203181926\n",
      "break: 0.00405468675198 > 0.0040203181926\n"
     ]
    }
   ],
   "source": [
    "#Training neural network for SubCategory part\n",
    "shidden_neurons =400\n",
    "np.random.seed(5)\n",
    "stheta1 = 2*np.random.random((len(X[0]), shidden_neurons)) - 1\n",
    "stheta2 = 2*np.random.random((shidden_neurons, len(subcat))) - 1\n",
    "#theta1.size\n",
    "slamda = 8\n",
    "\n",
    "#def train(X, y, hidden_neurons=400, alpha=0.0045, epochs=1000):\n",
    "\n",
    "\n",
    "sX = (train_data_features)\n",
    "sy = (output_subcat)\n",
    "sepochs = 1000\n",
    "salpha = .001\n",
    "sdell_theta1 = np.zeros_like(stheta1)\n",
    "sdell_theta2 = np.zeros_like(stheta2)\n",
    "slast_mean_error = 1\n",
    "start_X = sX[1:1500]\n",
    "sfinal_Y = sy[1:1500]\n",
    "for j in iter(range(sepochs+1)):\n",
    "    slayer_2 = sigmoid(np.dot(start_X, stheta1))\n",
    "    slayer_3 = sigmoid(np.dot(slayer_2, stheta2))\n",
    "    slayer_3_error =   sfinal_Y - slayer_3\n",
    "    if (j% 10) == 0 and j > 5:\n",
    "         # if this 10k iteration's error is greater than the last iteration, break out\n",
    "        if np.mean(np.abs(slayer_3_error)) < slast_mean_error:\n",
    "            print (\"delta after \"+str(j)+\" iterations:\" + str(np.mean(np.abs(slayer_3_error))) )\n",
    "            slast_mean_error = np.mean(np.abs(slayer_3_error))\n",
    "        else:\n",
    "            print (\"break:\", np.mean(np.abs(slayer_3_error)), \">\", slast_mean_error )\n",
    "            break\n",
    "\n",
    "    slayer_2_error = (slayer_3_error.dot(stheta2.T))*sigmoid_output_to_derivative(slayer_2)\n",
    "    #layer_3_delta_sigma = layer_3_error * sigmoid_output_to_derivative(layer_2)\n",
    "    #layer_2_error = layer_3_delta_sigma.dot(theta2.T)\n",
    "    #layer_2_delta_sigma = layer_2_error * sigmoid_output_to_derivative(layer_2)\n",
    "        \n",
    "    sdell_theta2 = (slayer_2.T.dot(slayer_3_error))\n",
    "    sdell_theta2 += slamda*stheta2\n",
    "    sdell_theta1 = (start_X.T.dot(slayer_2_error))\n",
    "    sdell_theta1 += slamda*stheta1\n",
    "    stheta1 += salpha * sdell_theta1\n",
    "    stheta2 += salpha * sdell_theta2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do you address a Chinese person ?\n",
      "\n",
      "manner\n",
      "47 subcategory ['cremat', 'manner', 'animal', 'exp', 'ind', 'gr', 'title', 'def', 'date', 'reason', 'event', 'state', 'desc', 'count', 'other', 'letter', 'religion', 'food', 'country', 'color', 'termeq', 'city', 'body', 'dismed', 'mount', 'money', 'product', 'period', 'substance', 'sport', 'plant', 'techmeth', 'volsize', 'instru', 'abb', 'speed', 'word', 'lang', 'perc', 'code', 'dist', 'temp', 'symbol', 'ord', 'veh', 'weight', 'currency']\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "#print (theta1.size)\n",
    "#Result check\n",
    "n=2000\n",
    "l0 = sX[n]\n",
    "print (training['sentence'][n+1])\n",
    "print (training['subcategory'][n+1])\n",
    "print (len(subcat), \"subcategory\",subcat)\n",
    "# matrix multiplication of input and hidden layer\n",
    "l1 = sigmoid(np.dot(l0, stheta1))\n",
    "# output layer\n",
    "l2 = sigmoid(np.dot(l1, stheta2))\n",
    "\n",
    "print (l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
